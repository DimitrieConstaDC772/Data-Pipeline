# End-to-End Data Pipeline and Dashboard Project

This repository showcases a complete data workflow that includes **Python ETL scripts**, **Airflow orchestration**, **dbt transformations**, **Docker containerization**, and a **Power BI dashboard** for visualization.

---

## ğŸ“ Project Structure
```
project-root/
â”œâ”€â”€ dags/
â”‚ â”œâ”€â”€ pipelines_dag.py
â”œâ”€â”€ dbt/
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ dims/
â”‚ â”‚ â”‚ â””â”€â”€ dim_company_insights.sql
â”‚ â”‚ â”œâ”€â”€ facts/
â”‚ â”‚ â”‚ â”œâ”€â”€ fact_sentiment.sql
â”‚ â”‚ â”‚ â””â”€â”€ fact_share_price.sql
â”‚ â”‚ â””â”€â”€ schema.yml
â”‚ â””â”€â”€ dbt_project.yml
â”œâ”€â”€ docker/
â”‚ â”œâ”€â”€ docker-compose.yaml
â”‚ â””â”€â”€ Dockerfile
â”œâ”€â”€ reports/
â”‚ â”œâ”€â”€ dashboard.pbix
â”‚ â””â”€â”€ screenshots/
â”œâ”€â”€ requirements/
â”‚ â”œâ”€â”€ requirements.txt
â”‚ â””â”€â”€ requirements_dbt.txt
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ news_data.py
â”‚ â””â”€â”€ price_data.py
â”œâ”€â”€ .env.example # Example environment variables
â”œâ”€â”€ LICENCE
â””â”€â”€ README.md
```
---

## Technologies Used

- **Python** â€“ ETL scripts and data processing
- **Airflow** â€“ DAG orchestration for automated pipelines
- **dbt** â€“ Data transformations and modeling
- **Docker & docker-compose** â€“ Containerized development environment
- **Power BI** â€“ Interactive dashboards for reporting

---

# Setup Instructions

---

## 1ï¸âƒ£ Clone the repository

**Description:** Get a local copy of the project.

**Instructions:**
- Clone the repository to your local machine.
- Navigate into the project folder.

**Commands:**
```bash
git clone https://github.com/DimitrieConstaDC772/Data-Pipeline.git
cd your-repo
```

## 2ï¸âƒ£ Create your `.env` file

**Description:** Set up environment variables for local development.

**Instructions:**
- Copy the example `.env` file to create your own `.env`.
- Edit `.env` to add your local secrets paths and Airflow Fernet key.

**Commands:**
```bash
cp .env.example .env
nano .env
```

## 3ï¸âƒ£ Start the environment with Docker

**Description:** Run the full containerized environment.

**Instructions:**
- Start Docker containers using docker-compose.
- Airflow webserver will be available at [http://localhost:8080](http://localhost:8080).
- DAGs will automatically load from the `dags/` folder.
- dbt models are mounted into the container and can be run inside Airflow tasks.

**Commands:**
```bash
docker-compose up
```

## 4ï¸âƒ£ Power BI Dashboard

**Description:** Access the reporting dashboard.

**Instructions:**
- Open `reports/dashboard.pbix` in Power BI Desktop.
- Use the screenshots in `reports/screenshots/` as a preview of the dashboard pages.

**Commands:**  
_None_


